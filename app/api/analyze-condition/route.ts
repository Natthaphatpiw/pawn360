import { NextRequest, NextResponse } from 'next/server';
import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY || '',
});

// Agent 3: Analyze condition from images (moved from estimate route)
async function analyzeConditionFromImages(images: string[]): Promise<{ score: number; reason: string }> {
  if (!images || images.length === 0) {
    return {
      score: 0.5,
      reason: '‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô'
    };
  }

  try {
    // Use OpenAI Vision API to analyze condition from images
    const prompt = `‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏à‡∏≤‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤ ‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å 0.0 ‡∏ñ‡∏∂‡∏á 1.0 ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏™‡∏±‡πâ‡∏ô‡πÜ

‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏†‡∏≤‡∏û:
- 1.0 = ‡∏™‡∏†‡∏≤‡∏û‡∏î‡∏µ‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏° ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡πà‡∏≠‡∏á‡∏£‡∏≠‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
- 0.8 = ‡∏™‡∏†‡∏≤‡∏û‡∏î‡∏µ‡∏°‡∏≤‡∏Å ‡∏°‡∏µ‡∏£‡πà‡∏≠‡∏á‡∏£‡∏≠‡∏¢‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏õ‡∏Å‡∏ï‡∏¥
- 0.6 = ‡∏™‡∏†‡∏≤‡∏û‡∏î‡∏µ ‡∏°‡∏µ‡∏£‡πà‡∏≠‡∏á‡∏£‡∏≠‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÄ‡∏´‡πá‡∏ô‡πÑ‡∏î‡πâ‡∏ä‡∏±‡∏î‡πÅ‡∏ï‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏õ‡∏Å‡∏ï‡∏¥
- 0.4 = ‡∏™‡∏†‡∏≤‡∏û‡∏û‡∏≠‡πÉ‡∏ä‡πâ ‡∏°‡∏µ‡∏£‡πà‡∏≠‡∏á‡∏£‡∏≠‡∏¢‡πÅ‡∏•‡∏∞‡∏ï‡∏≥‡∏´‡∏ô‡∏¥‡∏ó‡∏µ‡πà‡πÄ‡∏´‡πá‡∏ô‡πÑ‡∏î‡πâ‡∏ä‡∏±‡∏î
- 0.2 = ‡∏™‡∏†‡∏≤‡∏û‡πÑ‡∏°‡πà‡∏î‡∏µ ‡∏°‡∏µ‡∏ï‡∏≥‡∏´‡∏ô‡∏¥‡πÅ‡∏•‡∏∞‡∏£‡πà‡∏≠‡∏á‡∏£‡∏≠‡∏¢‡∏°‡∏≤‡∏Å
- 0.0 = ‡∏™‡∏†‡∏≤‡∏û‡πÄ‡∏•‡∏ß‡∏°‡∏≤‡∏Å ‡πÅ‡∏ó‡∏ö‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ

‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏à‡∏£‡∏¥‡∏á (‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏°‡∏±‡∏Å‡∏à‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏™‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡∏ï‡∏ô‡πÄ‡∏≠‡∏á‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏à‡∏£‡∏¥‡∏á)

‡∏ï‡∏≠‡∏ö‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö JSON:
{
  "score": 0.85,
  "reason": "‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏™‡∏†‡∏≤‡∏û‡∏î‡∏µ‡∏°‡∏≤‡∏Å ‡∏°‡∏µ‡∏£‡πà‡∏≠‡∏á‡∏£‡∏≠‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏õ‡∏Å‡∏ï‡∏¥ ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ï‡∏≥‡∏´‡∏ô‡∏¥‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç ‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏™‡∏†‡∏≤‡∏û‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå"
}`;

    // Prepare messages with images for Vision API
    const messages: any[] = [
      {
        role: 'user',
        content: [
          { type: 'text', text: prompt }
        ]
      }
    ];

    // Add up to 4 images (limit for Vision API)
    const maxImages = Math.min(images.length, 4);
    for (let i = 0; i < maxImages; i++) {
      messages[0].content.push({
        type: 'image_url',
        image_url: {
          url: images[i],
          detail: 'low' // Use low detail for faster processing
        }
      });
    }

    const response = await openai.chat.completions.create({
      model: 'gpt-4o-mini', // Vision-capable model
      messages: messages,
      max_tokens: 300,
      temperature: 0.2,
    });

    const content = response.choices[0]?.message?.content || '';

    // Try to parse JSON response
    try {
      const parsed = JSON.parse(content);
      return {
        score: Math.max(0, Math.min(1, parsed.score || 0.5)),
        reason: parsed.reason || '‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏à‡∏≤‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÅ‡∏•‡πâ‡∏ß'
      };
    } catch {
      // If JSON parsing fails, extract score and reason from text
      const scoreMatch = content.match(/score["\s:]+([0-9.]+)/i);
      const reasonMatch = content.match(/reason["\s:]+["']([^"']+)["']/i);

      const score = scoreMatch ? parseFloat(scoreMatch[1]) : 0.5;
      const reason = reasonMatch ? reasonMatch[1] : content.replace(/score["\s:]+[0-9.]+/i, '').trim() || '‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏à‡∏≤‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÅ‡∏•‡πâ‡∏ß';

      return {
        score: Math.max(0, Math.min(1, score)),
        reason: reason
      };
    }
  } catch (error) {
    console.error('Error analyzing condition with Vision API:', error);
    // Fallback analysis
    return {
      score: 0.5,
      reason: '‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÑ‡∏î‡πâ ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô'
    };
  }
}

export async function POST(request: NextRequest) {
  try {
    if (!process.env.OPENAI_API_KEY) {
      return NextResponse.json(
        { error: 'OpenAI API key not configured' },
        { status: 500 }
      );
    }

    const body = await request.json();
    const { images } = body;

    if (!images || !Array.isArray(images) || images.length === 0) {
      return NextResponse.json({ error: '‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 1 ‡∏£‡∏π‡∏õ' }, { status: 400 });
    }

    console.log('üîÑ Analyzing condition from images...');
    const conditionResult = await analyzeConditionFromImages(images);
    console.log('‚úÖ Condition analysis complete:', conditionResult);

    return NextResponse.json(conditionResult);
  } catch (error) {
    console.error('Error analyzing condition:', error);
    return NextResponse.json({ error: '‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏†‡∏≤‡∏û' }, { status: 500 });
  }
}
